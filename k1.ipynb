{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca9eb2-6843-4734-aa77-e00d4527517f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57593358-1913-4d8b-a5f2-e551d4653786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bf2df-673d-4c76-a97e-17c72ffa79c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc562f01-85e1-4019-96ff-b27e4c00c7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4610cb-e8ff-4217-8381-5f6445f82f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d125-188e-471c-a636-2695ff7acc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ee463-9979-4ed5-b1b1-25f2aaa66f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebce89-a6ef-4e0f-ab1d-200251b6697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465f19c-7dfe-42a1-917f-76568ee38ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd0961-c87f-40e0-9601-5b2999e82fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76360b24-646f-4a72-a9ab-dc44ae64bf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f1657-e0fc-4172-9eac-5f22a7b13673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfee34d-9112-4926-80fd-0928d45f706d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f16b81-9627-4025-bd6d-b734dc78f45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc304aa-47db-4de1-b697-430e77cd01d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58bc99-4efc-45d9-b13c-8490ac44477c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f614b2-5c46-49cc-96c4-a435a31a1d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884164c-fc67-44ef-8874-c6c002e9825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e45ac-5c00-46c3-b5de-9000b1602425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01325b-5c6d-4ae6-b646-984f9eeeacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d79b64-1b4e-4e70-969e-4a91f0fd63f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e1319-23f8-4395-bb5b-b6dc266762d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5481058-018e-41e4-baec-03996d1e3df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33418c3-f57d-4973-9448-acdfa46aace1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41ac55-e6e5-4f69-8542-1663ca0ab54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db93a9f-2431-4963-a51b-da7272d17dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e90a9-f9cb-4740-bca9-0e8dee34920d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addcb7b-7591-4ab9-b4b5-a327d8ecc65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf4fbb-4997-49d7-9e1a-0c55a24c1a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7045b3-6535-41a0-ae26-27b87605c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b6e6c-bb9f-4fbd-bbe7-e6ca5a0f971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c497da-7be6-4b56-bb6e-a86c80e785ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e9a7c-d49f-4eca-9d7e-0d12d71c97be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977712f-5464-4d76-8b2f-5d57ccb60e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd864a9-0799-479e-88f4-b357fcd759ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fef20-516f-420b-bac3-fff77fac72c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c06c31-c3dd-489d-8ab8-3241db54c63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b56005-8b8f-4370-8af4-ce7d37252ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d6066-d7d1-4ff2-99ed-440e51bed6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e202af5-ff79-48c8-b655-66e2193daf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ab46c-45ff-4fc6-8552-d5377c9a15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9f94b-116d-4165-b394-c7034d7cfa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856680-c8a5-43a9-9fa3-c51b5c6c8ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb997d-2e2b-441a-a419-5d299f38be93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89aca4-45da-48cb-8a09-2d6abf4b31e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a86be0-6ca2-45df-a6a4-db8dc6d50f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef77cc-7866-46a2-b857-de56dab40d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35f703-c766-4bfd-a484-1ae8ff5c2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5c242-ec88-4f9d-bc73-b8b64aca7a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db114dde-369e-4c1e-a9af-d07093c55e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68a9f6-4f47-4992-ab4d-22d407dd6b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71c92-8b02-48a7-85c5-283a25e02889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139183e1-b9bb-44ea-9e8d-4f019ea20241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf708f-13cd-4a6e-9397-ebc856f91a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2607630-b70e-4f5d-84f7-ff2c6c7dea2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c23b36-3ae3-4927-a6ca-e0dbfc70afb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f6949-1935-4ace-b9ba-621e741e8aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf328c-bd32-4f7a-ada4-3a74df339533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc39a30-756a-49d2-b320-0aee2e152a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1734b5f-1678-4ea5-8e68-ec1008a66ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf96b2e-d2c3-4dd6-b13e-e95e83f6e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b856024e-4cd9-4a45-805b-f68e5647e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4133 - loss: 4.8025\n",
      "Epoch 2/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 1.3151\n",
      "Epoch 3/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6058 - loss: 0.8226\n",
      "Epoch 4/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 0.7839\n",
      "Epoch 5/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5868 - loss: 0.7084\n",
      "Epoch 6/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 0.7148\n",
      "Epoch 7/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6198 - loss: 0.6996\n",
      "Epoch 8/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6373 - loss: 0.6242\n",
      "Epoch 9/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6661\n",
      "Epoch 10/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6352 - loss: 0.6461\n",
      "Epoch 11/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6223 - loss: 0.6453\n",
      "Epoch 12/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 0.6000\n",
      "Epoch 13/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6844 - loss: 0.6092\n",
      "Epoch 14/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6328 - loss: 0.6425\n",
      "Epoch 15/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6820 - loss: 0.6042\n",
      "Epoch 16/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.5906\n",
      "Epoch 17/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6786 - loss: 0.6006\n",
      "Epoch 18/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6699 - loss: 0.6055\n",
      "Epoch 19/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6782 - loss: 0.5915\n",
      "Epoch 20/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.5822\n",
      "Epoch 21/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6898 - loss: 0.6128\n",
      "Epoch 22/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6942 - loss: 0.5972\n",
      "Epoch 23/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6989 - loss: 0.5921\n",
      "Epoch 24/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6921 - loss: 0.5977\n",
      "Epoch 25/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.5949\n",
      "Epoch 26/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6942 - loss: 0.5746\n",
      "Epoch 27/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.5845\n",
      "Epoch 28/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.5744\n",
      "Epoch 29/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7132 - loss: 0.5843\n",
      "Epoch 30/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6973 - loss: 0.5902\n",
      "Epoch 31/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6660 - loss: 0.6095\n",
      "Epoch 32/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7009 - loss: 0.5818\n",
      "Epoch 33/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5522\n",
      "Epoch 34/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6975 - loss: 0.5560\n",
      "Epoch 35/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7037 - loss: 0.5651\n",
      "Epoch 36/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.5533\n",
      "Epoch 37/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7003 - loss: 0.5850\n",
      "Epoch 38/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.5733\n",
      "Epoch 39/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7164 - loss: 0.5519\n",
      "Epoch 40/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5410\n",
      "Epoch 41/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.5496\n",
      "Epoch 42/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5446\n",
      "Epoch 43/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6946 - loss: 0.5775\n",
      "Epoch 44/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.5334\n",
      "Epoch 45/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7101 - loss: 0.5789\n",
      "Epoch 46/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.5582\n",
      "Epoch 47/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7138 - loss: 0.5497\n",
      "Epoch 48/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.5580\n",
      "Epoch 49/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.5577\n",
      "Epoch 50/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7072 - loss: 0.5803\n",
      "Epoch 51/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.5732\n",
      "Epoch 52/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 0.5663\n",
      "Epoch 53/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5271\n",
      "Epoch 54/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.5500\n",
      "Epoch 55/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7294 - loss: 0.5428\n",
      "Epoch 56/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.5630\n",
      "Epoch 57/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5178\n",
      "Epoch 58/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7306 - loss: 0.5497\n",
      "Epoch 59/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7039 - loss: 0.5545\n",
      "Epoch 60/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.5347\n",
      "Epoch 61/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7171 - loss: 0.5411\n",
      "Epoch 62/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.5502\n",
      "Epoch 63/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7113 - loss: 0.5498\n",
      "Epoch 64/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.5481\n",
      "Epoch 65/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.5186\n",
      "Epoch 66/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6897 - loss: 0.5811\n",
      "Epoch 67/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.5603\n",
      "Epoch 68/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.5510\n",
      "Epoch 69/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.5279\n",
      "Epoch 70/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.5173\n",
      "Epoch 71/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.5590\n",
      "Epoch 72/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.5164\n",
      "Epoch 73/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.5125\n",
      "Epoch 74/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.5346\n",
      "Epoch 75/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 0.5481\n",
      "Epoch 76/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4932\n",
      "Epoch 77/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7524 - loss: 0.5102\n",
      "Epoch 78/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.5272\n",
      "Epoch 79/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.5140\n",
      "Epoch 80/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.5545\n",
      "Epoch 81/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.5120\n",
      "Epoch 82/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.5312\n",
      "Epoch 83/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.5170\n",
      "Epoch 84/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.5611\n",
      "Epoch 85/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.5270\n",
      "Epoch 86/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.4977\n",
      "Epoch 87/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.5122\n",
      "Epoch 88/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4969\n",
      "Epoch 89/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5396\n",
      "Epoch 90/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.5998\n",
      "Epoch 91/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5483\n",
      "Epoch 92/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.5680\n",
      "Epoch 93/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5347\n",
      "Epoch 94/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.5193\n",
      "Epoch 95/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7029 - loss: 0.5552\n",
      "Epoch 96/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5225\n",
      "Epoch 97/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.5034\n",
      "Epoch 98/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.5263\n",
      "Epoch 99/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.5219\n",
      "Epoch 100/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.5175\n",
      "Epoch 101/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.5417\n",
      "Epoch 102/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.5381\n",
      "Epoch 103/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7239 - loss: 0.5382\n",
      "Epoch 104/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7619 - loss: 0.5068\n",
      "Epoch 105/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.5190\n",
      "Epoch 106/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5107\n",
      "Epoch 107/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.5465\n",
      "Epoch 108/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.5276\n",
      "Epoch 109/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.4957\n",
      "Epoch 110/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.4974\n",
      "Epoch 111/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7768 - loss: 0.4857\n",
      "Epoch 112/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 0.4940\n",
      "Epoch 113/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 0.4913\n",
      "Epoch 114/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4730\n",
      "Epoch 115/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.4909\n",
      "Epoch 116/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.5020\n",
      "Epoch 117/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.5263\n",
      "Epoch 118/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.4946\n",
      "Epoch 119/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7485 - loss: 0.5104\n",
      "Epoch 120/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.5052\n",
      "Epoch 121/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5028\n",
      "Epoch 122/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7678 - loss: 0.4965\n",
      "Epoch 123/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.5031\n",
      "Epoch 124/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.5004\n",
      "Epoch 125/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4768\n",
      "Epoch 126/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4797\n",
      "Epoch 127/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4922\n",
      "Epoch 128/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.5133\n",
      "Epoch 129/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4941\n",
      "Epoch 130/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5260\n",
      "Epoch 131/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5023\n",
      "Epoch 132/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7312 - loss: 0.5244\n",
      "Epoch 133/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.5128\n",
      "Epoch 134/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.5275\n",
      "Epoch 135/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.5311\n",
      "Epoch 136/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.4929\n",
      "Epoch 137/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.4995\n",
      "Epoch 138/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7156 - loss: 0.5451\n",
      "Epoch 139/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.5092\n",
      "Epoch 140/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.5029\n",
      "Epoch 141/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.5090\n",
      "Epoch 142/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.5114\n",
      "Epoch 143/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 0.4978\n",
      "Epoch 144/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.5260\n",
      "Epoch 145/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4711\n",
      "Epoch 146/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7432 - loss: 0.5199\n",
      "Epoch 147/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.5152\n",
      "Epoch 148/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.4862\n",
      "Epoch 149/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.4833\n",
      "Epoch 150/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.4671\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# load the dataset (skip header row)\n",
    "dataset = loadtxt(r\"C:\\Users\\Deepa\\Desktop\\pracs\\diabetes.csv\", delimiter=',', skiprows=1)\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=1)\n",
    "\n",
    "# make class predictions\n",
    "predictions = (model.predict(X).flatten() > 0.5).astype(int)\n",
    "\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51cce104-4651-4fda-a37d-f60ea47b6de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.3631 - loss: 2.2716 - val_accuracy: 0.3000 - val_loss: 1.9357\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3138 - loss: 1.7189 - val_accuracy: 0.3000 - val_loss: 1.4121\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3629 - loss: 1.2694 - val_accuracy: 0.4333 - val_loss: 1.1365\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4939 - loss: 1.0925 - val_accuracy: 0.3667 - val_loss: 0.9933\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3961 - loss: 0.9932 - val_accuracy: 0.3667 - val_loss: 0.9088\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3208 - loss: 0.9266 - val_accuracy: 0.3667 - val_loss: 0.8387\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4013 - loss: 0.8839 - val_accuracy: 0.6667 - val_loss: 0.7742\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6972 - loss: 0.7737 - val_accuracy: 0.8333 - val_loss: 0.7081\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8616 - loss: 0.7031 - val_accuracy: 0.9000 - val_loss: 0.6602\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9555 - loss: 0.6310 - val_accuracy: 0.9000 - val_loss: 0.6111\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9381 - loss: 0.6143 - val_accuracy: 0.9000 - val_loss: 0.5779\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9335 - loss: 0.5600 - val_accuracy: 0.9000 - val_loss: 0.5538\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9706 - loss: 0.5124 - val_accuracy: 0.9000 - val_loss: 0.5299\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9488 - loss: 0.5262 - val_accuracy: 0.9000 - val_loss: 0.5134\n",
      "Epoch 15/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9389 - loss: 0.5034 - val_accuracy: 0.9333 - val_loss: 0.5013\n",
      "Epoch 16/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9615 - loss: 0.4804 - val_accuracy: 0.9333 - val_loss: 0.4826\n",
      "Epoch 17/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9193 - loss: 0.4815 - val_accuracy: 0.9333 - val_loss: 0.4695\n",
      "Epoch 18/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9280 - loss: 0.4596 - val_accuracy: 0.9333 - val_loss: 0.4549\n",
      "Epoch 19/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9526 - loss: 0.4611 - val_accuracy: 0.9333 - val_loss: 0.4427\n",
      "Epoch 20/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9338 - loss: 0.4573 - val_accuracy: 0.9667 - val_loss: 0.4321\n",
      "Epoch 21/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9086 - loss: 0.4344 - val_accuracy: 0.9667 - val_loss: 0.4263\n",
      "Epoch 22/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9347 - loss: 0.4221 - val_accuracy: 0.9000 - val_loss: 0.4091\n",
      "Epoch 23/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9534 - loss: 0.4294 - val_accuracy: 0.9667 - val_loss: 0.4038\n",
      "Epoch 24/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9564 - loss: 0.4012 - val_accuracy: 0.9667 - val_loss: 0.3973\n",
      "Epoch 25/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9565 - loss: 0.3680 - val_accuracy: 0.9667 - val_loss: 0.3800\n",
      "Epoch 26/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9200 - loss: 0.4083 - val_accuracy: 0.9667 - val_loss: 0.3779\n",
      "Epoch 27/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9605 - loss: 0.3568 - val_accuracy: 0.9667 - val_loss: 0.3635\n",
      "Epoch 28/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9540 - loss: 0.3556 - val_accuracy: 0.9667 - val_loss: 0.3627\n",
      "Epoch 29/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9397 - loss: 0.3698 - val_accuracy: 0.9667 - val_loss: 0.3495\n",
      "Epoch 30/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9652 - loss: 0.3281 - val_accuracy: 0.9667 - val_loss: 0.3403\n",
      "Epoch 31/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9076 - loss: 0.3632 - val_accuracy: 0.9667 - val_loss: 0.3390\n",
      "Epoch 32/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9767 - loss: 0.3057 - val_accuracy: 0.9667 - val_loss: 0.3264\n",
      "Epoch 33/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9494 - loss: 0.3159 - val_accuracy: 0.9667 - val_loss: 0.3258\n",
      "Epoch 34/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9794 - loss: 0.3373 - val_accuracy: 0.9667 - val_loss: 0.3182\n",
      "Epoch 35/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9604 - loss: 0.3123 - val_accuracy: 1.0000 - val_loss: 0.3079\n",
      "Epoch 36/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9512 - loss: 0.3209 - val_accuracy: 0.9667 - val_loss: 0.3012\n",
      "Epoch 37/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9868 - loss: 0.2883 - val_accuracy: 0.9667 - val_loss: 0.3099\n",
      "Epoch 38/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9322 - loss: 0.2989 - val_accuracy: 1.0000 - val_loss: 0.2902\n",
      "Epoch 39/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9433 - loss: 0.2660 - val_accuracy: 1.0000 - val_loss: 0.2857\n",
      "Epoch 40/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9717 - loss: 0.2665 - val_accuracy: 1.0000 - val_loss: 0.2817\n",
      "Epoch 41/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9680 - loss: 0.2582 - val_accuracy: 0.9667 - val_loss: 0.2796\n",
      "Epoch 42/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9767 - loss: 0.2664 - val_accuracy: 1.0000 - val_loss: 0.2708\n",
      "Epoch 43/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9631 - loss: 0.2555 - val_accuracy: 0.9667 - val_loss: 0.2689\n",
      "Epoch 44/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9708 - loss: 0.2487 - val_accuracy: 1.0000 - val_loss: 0.2627\n",
      "Epoch 45/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9616 - loss: 0.2443 - val_accuracy: 1.0000 - val_loss: 0.2577\n",
      "Epoch 46/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9595 - loss: 0.2313 - val_accuracy: 1.0000 - val_loss: 0.2516\n",
      "Epoch 47/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9455 - loss: 0.2552 - val_accuracy: 1.0000 - val_loss: 0.2486\n",
      "Epoch 48/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9503 - loss: 0.2513 - val_accuracy: 0.9667 - val_loss: 0.2466\n",
      "Epoch 49/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9801 - loss: 0.2293 - val_accuracy: 1.0000 - val_loss: 0.2388\n",
      "Epoch 50/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.2546 - val_accuracy: 1.0000 - val_loss: 0.2355\n",
      "Epoch 51/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9631 - loss: 0.2227 - val_accuracy: 1.0000 - val_loss: 0.2340\n",
      "Epoch 52/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9755 - loss: 0.2004 - val_accuracy: 0.9667 - val_loss: 0.2291\n",
      "Epoch 53/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9555 - loss: 0.1897 - val_accuracy: 0.9667 - val_loss: 0.2325\n",
      "Epoch 54/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9849 - loss: 0.1852 - val_accuracy: 1.0000 - val_loss: 0.2232\n",
      "Epoch 55/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9755 - loss: 0.2213 - val_accuracy: 1.0000 - val_loss: 0.2177\n",
      "Epoch 56/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9665 - loss: 0.2006 - val_accuracy: 1.0000 - val_loss: 0.2128\n",
      "Epoch 57/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9715 - loss: 0.2209 - val_accuracy: 0.9667 - val_loss: 0.2196\n",
      "Epoch 58/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9658 - loss: 0.2082 - val_accuracy: 1.0000 - val_loss: 0.2069\n",
      "Epoch 59/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9451 - loss: 0.2286 - val_accuracy: 1.0000 - val_loss: 0.2044\n",
      "Epoch 60/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9891 - loss: 0.1809 - val_accuracy: 1.0000 - val_loss: 0.2044\n",
      "Epoch 61/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9666 - loss: 0.1963 - val_accuracy: 1.0000 - val_loss: 0.2008\n",
      "Epoch 62/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9831 - loss: 0.1831 - val_accuracy: 1.0000 - val_loss: 0.1948\n",
      "Epoch 63/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9464 - loss: 0.1993 - val_accuracy: 0.9667 - val_loss: 0.2018\n",
      "Epoch 64/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9682 - loss: 0.1720 - val_accuracy: 1.0000 - val_loss: 0.1887\n",
      "Epoch 65/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9457 - loss: 0.2053 - val_accuracy: 0.9667 - val_loss: 0.1957\n",
      "Epoch 66/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.1972 - val_accuracy: 1.0000 - val_loss: 0.1871\n",
      "Epoch 67/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9885 - loss: 0.1652 - val_accuracy: 1.0000 - val_loss: 0.1828\n",
      "Epoch 68/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9843 - loss: 0.1420 - val_accuracy: 1.0000 - val_loss: 0.1809\n",
      "Epoch 69/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9929 - loss: 0.1541 - val_accuracy: 1.0000 - val_loss: 0.1810\n",
      "Epoch 70/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9432 - loss: 0.1723 - val_accuracy: 1.0000 - val_loss: 0.1771\n",
      "Epoch 71/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9507 - loss: 0.1861 - val_accuracy: 1.0000 - val_loss: 0.1716\n",
      "Epoch 72/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9538 - loss: 0.1717 - val_accuracy: 0.9667 - val_loss: 0.1768\n",
      "Epoch 73/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9517 - loss: 0.1821 - val_accuracy: 1.0000 - val_loss: 0.1688\n",
      "Epoch 74/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9701 - loss: 0.1597 - val_accuracy: 1.0000 - val_loss: 0.1653\n",
      "Epoch 75/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9629 - loss: 0.1729 - val_accuracy: 0.9333 - val_loss: 0.1826\n",
      "Epoch 76/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9761 - loss: 0.1373 - val_accuracy: 1.0000 - val_loss: 0.1622\n",
      "Epoch 77/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9661 - loss: 0.1576 - val_accuracy: 1.0000 - val_loss: 0.1586\n",
      "Epoch 78/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9699 - loss: 0.1496 - val_accuracy: 0.9333 - val_loss: 0.1801\n",
      "Epoch 79/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9836 - loss: 0.1437 - val_accuracy: 1.0000 - val_loss: 0.1547\n",
      "Epoch 80/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9353 - loss: 0.1874 - val_accuracy: 1.0000 - val_loss: 0.1582\n",
      "Epoch 81/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9693 - loss: 0.1501 - val_accuracy: 1.0000 - val_loss: 0.1519\n",
      "Epoch 82/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9469 - loss: 0.1640 - val_accuracy: 1.0000 - val_loss: 0.1582\n",
      "Epoch 83/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9517 - loss: 0.1686 - val_accuracy: 1.0000 - val_loss: 0.1493\n",
      "Epoch 84/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9827 - loss: 0.1182 - val_accuracy: 1.0000 - val_loss: 0.1479\n",
      "Epoch 85/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9580 - loss: 0.1499 - val_accuracy: 0.9667 - val_loss: 0.1613\n",
      "Epoch 86/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9760 - loss: 0.1251 - val_accuracy: 1.0000 - val_loss: 0.1435\n",
      "Epoch 87/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9814 - loss: 0.1255 - val_accuracy: 1.0000 - val_loss: 0.1518\n",
      "Epoch 88/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9689 - loss: 0.1346 - val_accuracy: 1.0000 - val_loss: 0.1479\n",
      "Epoch 89/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9735 - loss: 0.1387 - val_accuracy: 1.0000 - val_loss: 0.1400\n",
      "Epoch 90/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.1141 - val_accuracy: 1.0000 - val_loss: 0.1402\n",
      "Epoch 91/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9871 - loss: 0.1128 - val_accuracy: 1.0000 - val_loss: 0.1446\n",
      "Epoch 92/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.1321 - val_accuracy: 1.0000 - val_loss: 0.1405\n",
      "Epoch 93/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9776 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.1341\n",
      "Epoch 94/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9730 - loss: 0.1277 - val_accuracy: 1.0000 - val_loss: 0.1372\n",
      "Epoch 95/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9710 - loss: 0.1407 - val_accuracy: 1.0000 - val_loss: 0.1376\n",
      "Epoch 96/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9872 - loss: 0.1118 - val_accuracy: 1.0000 - val_loss: 0.1289\n",
      "Epoch 97/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9765 - loss: 0.1217 - val_accuracy: 1.0000 - val_loss: 0.1386\n",
      "Epoch 98/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9894 - loss: 0.0997 - val_accuracy: 1.0000 - val_loss: 0.1304\n",
      "Epoch 99/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9682 - loss: 0.1370 - val_accuracy: 1.0000 - val_loss: 0.1266\n",
      "Epoch 100/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9719 - loss: 0.1212 - val_accuracy: 1.0000 - val_loss: 0.1262\n",
      "Epoch 101/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9690 - loss: 0.1239 - val_accuracy: 1.0000 - val_loss: 0.1369\n",
      "Epoch 102/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9680 - loss: 0.1274 - val_accuracy: 1.0000 - val_loss: 0.1245\n",
      "Epoch 103/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9832 - loss: 0.1284 - val_accuracy: 1.0000 - val_loss: 0.1206\n",
      "Epoch 104/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9814 - loss: 0.1263 - val_accuracy: 0.9667 - val_loss: 0.1413\n",
      "Epoch 105/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9329 - loss: 0.1375 - val_accuracy: 1.0000 - val_loss: 0.1254\n",
      "Epoch 106/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9774 - loss: 0.1123 - val_accuracy: 1.0000 - val_loss: 0.1203\n",
      "Epoch 107/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9786 - loss: 0.0992 - val_accuracy: 1.0000 - val_loss: 0.1185\n",
      "Epoch 108/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9575 - loss: 0.1050 - val_accuracy: 1.0000 - val_loss: 0.1303\n",
      "Epoch 109/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9572 - loss: 0.1112 - val_accuracy: 1.0000 - val_loss: 0.1140\n",
      "Epoch 110/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9868 - loss: 0.0957 - val_accuracy: 0.9667 - val_loss: 0.1328\n",
      "Epoch 111/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9697 - loss: 0.1182 - val_accuracy: 1.0000 - val_loss: 0.1159\n",
      "Epoch 112/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9677 - loss: 0.1020 - val_accuracy: 1.0000 - val_loss: 0.1186\n",
      "Epoch 113/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9876 - loss: 0.1112 - val_accuracy: 1.0000 - val_loss: 0.1149\n",
      "Epoch 114/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9657 - loss: 0.0995 - val_accuracy: 1.0000 - val_loss: 0.1212\n",
      "Epoch 115/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.1009 - val_accuracy: 1.0000 - val_loss: 0.1081\n",
      "Epoch 116/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9690 - loss: 0.1375 - val_accuracy: 1.0000 - val_loss: 0.1221\n",
      "Epoch 117/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.1264 - val_accuracy: 1.0000 - val_loss: 0.1098\n",
      "Epoch 118/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9860 - loss: 0.1004 - val_accuracy: 1.0000 - val_loss: 0.1159\n",
      "Epoch 119/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9766 - loss: 0.1457 - val_accuracy: 1.0000 - val_loss: 0.1103\n",
      "Epoch 120/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9747 - loss: 0.1015 - val_accuracy: 1.0000 - val_loss: 0.1082\n",
      "Epoch 121/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9891 - loss: 0.0920 - val_accuracy: 1.0000 - val_loss: 0.1081\n",
      "Epoch 122/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9682 - loss: 0.1208 - val_accuracy: 1.0000 - val_loss: 0.1142\n",
      "Epoch 123/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9612 - loss: 0.1347 - val_accuracy: 1.0000 - val_loss: 0.1034\n",
      "Epoch 124/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.0908 - val_accuracy: 1.0000 - val_loss: 0.1226\n",
      "Epoch 125/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.1023 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
      "Epoch 126/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.1304 - val_accuracy: 1.0000 - val_loss: 0.1107\n",
      "Epoch 127/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9749 - loss: 0.0906 - val_accuracy: 1.0000 - val_loss: 0.1169\n",
      "Epoch 128/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9778 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.1003\n",
      "Epoch 129/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9856 - loss: 0.0973 - val_accuracy: 1.0000 - val_loss: 0.1085\n",
      "Epoch 130/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9510 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 0.0980\n",
      "Epoch 131/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9834 - loss: 0.0844 - val_accuracy: 1.0000 - val_loss: 0.1007\n",
      "Epoch 132/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9794 - loss: 0.1066 - val_accuracy: 0.9667 - val_loss: 0.1215\n",
      "Epoch 133/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9854 - loss: 0.0892 - val_accuracy: 1.0000 - val_loss: 0.0946\n",
      "Epoch 134/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9570 - loss: 0.1008 - val_accuracy: 1.0000 - val_loss: 0.1069\n",
      "Epoch 135/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9750 - loss: 0.0832 - val_accuracy: 1.0000 - val_loss: 0.1019\n",
      "Epoch 136/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9915 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.1047\n",
      "Epoch 137/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0941\n",
      "Epoch 138/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9766 - loss: 0.0850 - val_accuracy: 1.0000 - val_loss: 0.1018\n",
      "Epoch 139/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9404 - loss: 0.1505 - val_accuracy: 1.0000 - val_loss: 0.0977\n",
      "Epoch 140/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9759 - loss: 0.1176 - val_accuracy: 1.0000 - val_loss: 0.0904\n",
      "Epoch 141/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9718 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.1049\n",
      "Epoch 142/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9825 - loss: 0.0726 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
      "Epoch 143/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9605 - loss: 0.1305 - val_accuracy: 1.0000 - val_loss: 0.1003\n",
      "Epoch 144/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9464 - loss: 0.1334 - val_accuracy: 1.0000 - val_loss: 0.0889\n",
      "Epoch 145/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9747 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.0964\n",
      "Epoch 146/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9833 - loss: 0.0695 - val_accuracy: 1.0000 - val_loss: 0.0964\n",
      "Epoch 147/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9927 - loss: 0.0731 - val_accuracy: 1.0000 - val_loss: 0.0951\n",
      "Epoch 148/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9635 - loss: 0.0957 - val_accuracy: 1.0000 - val_loss: 0.0924\n",
      "Epoch 149/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.0956 - val_accuracy: 1.0000 - val_loss: 0.1027\n",
      "Epoch 150/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9778 - loss: 0.0758 - val_accuracy: 1.0000 - val_loss: 0.0907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 0.0907\n",
      "Test loss: 0.09070558845996857\n",
      "Test accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "#iris\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "Y = data.target  #Target (integer labels: 0, 1, 2)\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "#First hidden layer with 12 units, ReLU activation, and input_dim = 4 (since Iris dataset has 4 features)\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#Output layer with 3 units (for 3 classes) and softmax activation\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Compile the model using sparse categorical crossentropy (for integer labels) and accuracy metric\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Fit the model with the training data\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=10, validation_data=(X_test, Y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c506c799-9884-4a1b-91b2-31d1af1b2f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data : [5.1 3.5 1.4 0.2],label data:0\n",
      "input data : [4.9 3.  1.4 0.2],label data:0\n",
      "input data : [4.7 3.2 1.3 0.2],label data:0\n",
      "input data : [4.6 3.1 1.5 0.2],label data:0\n",
      "input data : [5.  3.6 1.4 0.2],label data:0\n",
      "input data : [5.4 3.9 1.7 0.4],label data:0\n",
      "input data : [4.6 3.4 1.4 0.3],label data:0\n",
      "input data : [5.  3.4 1.5 0.2],label data:0\n",
      "input data : [4.4 2.9 1.4 0.2],label data:0\n",
      "input data : [4.9 3.1 1.5 0.1],label data:0\n",
      "input data : [5.4 3.7 1.5 0.2],label data:0\n",
      "input data : [4.8 3.4 1.6 0.2],label data:0\n",
      "input data : [4.8 3.  1.4 0.1],label data:0\n",
      "input data : [4.3 3.  1.1 0.1],label data:0\n",
      "input data : [5.8 4.  1.2 0.2],label data:0\n",
      "input data : [5.7 4.4 1.5 0.4],label data:0\n",
      "input data : [5.4 3.9 1.3 0.4],label data:0\n",
      "input data : [5.1 3.5 1.4 0.3],label data:0\n",
      "input data : [5.7 3.8 1.7 0.3],label data:0\n",
      "input data : [5.1 3.8 1.5 0.3],label data:0\n",
      "input data : [5.4 3.4 1.7 0.2],label data:0\n",
      "input data : [5.1 3.7 1.5 0.4],label data:0\n",
      "input data : [4.6 3.6 1.  0.2],label data:0\n",
      "input data : [5.1 3.3 1.7 0.5],label data:0\n",
      "input data : [4.8 3.4 1.9 0.2],label data:0\n",
      "input data : [5.  3.  1.6 0.2],label data:0\n",
      "input data : [5.  3.4 1.6 0.4],label data:0\n",
      "input data : [5.2 3.5 1.5 0.2],label data:0\n",
      "input data : [5.2 3.4 1.4 0.2],label data:0\n",
      "input data : [4.7 3.2 1.6 0.2],label data:0\n",
      "input data : [4.8 3.1 1.6 0.2],label data:0\n",
      "input data : [5.4 3.4 1.5 0.4],label data:0\n",
      "input data : [5.2 4.1 1.5 0.1],label data:0\n",
      "input data : [5.5 4.2 1.4 0.2],label data:0\n",
      "input data : [4.9 3.1 1.5 0.2],label data:0\n",
      "input data : [5.  3.2 1.2 0.2],label data:0\n",
      "input data : [5.5 3.5 1.3 0.2],label data:0\n",
      "input data : [4.9 3.6 1.4 0.1],label data:0\n",
      "input data : [4.4 3.  1.3 0.2],label data:0\n",
      "input data : [5.1 3.4 1.5 0.2],label data:0\n",
      "input data : [5.  3.5 1.3 0.3],label data:0\n",
      "input data : [4.5 2.3 1.3 0.3],label data:0\n",
      "input data : [4.4 3.2 1.3 0.2],label data:0\n",
      "input data : [5.  3.5 1.6 0.6],label data:0\n",
      "input data : [5.1 3.8 1.9 0.4],label data:0\n",
      "input data : [4.8 3.  1.4 0.3],label data:0\n",
      "input data : [5.1 3.8 1.6 0.2],label data:0\n",
      "input data : [4.6 3.2 1.4 0.2],label data:0\n",
      "input data : [5.3 3.7 1.5 0.2],label data:0\n",
      "input data : [5.  3.3 1.4 0.2],label data:0\n",
      "input data : [7.  3.2 4.7 1.4],label data:1\n",
      "input data : [6.4 3.2 4.5 1.5],label data:1\n",
      "input data : [6.9 3.1 4.9 1.5],label data:1\n",
      "input data : [5.5 2.3 4.  1.3],label data:1\n",
      "input data : [6.5 2.8 4.6 1.5],label data:1\n",
      "input data : [5.7 2.8 4.5 1.3],label data:1\n",
      "input data : [6.3 3.3 4.7 1.6],label data:1\n",
      "input data : [4.9 2.4 3.3 1. ],label data:1\n",
      "input data : [6.6 2.9 4.6 1.3],label data:1\n",
      "input data : [5.2 2.7 3.9 1.4],label data:1\n",
      "input data : [5.  2.  3.5 1. ],label data:1\n",
      "input data : [5.9 3.  4.2 1.5],label data:1\n",
      "input data : [6.  2.2 4.  1. ],label data:1\n",
      "input data : [6.1 2.9 4.7 1.4],label data:1\n",
      "input data : [5.6 2.9 3.6 1.3],label data:1\n",
      "input data : [6.7 3.1 4.4 1.4],label data:1\n",
      "input data : [5.6 3.  4.5 1.5],label data:1\n",
      "input data : [5.8 2.7 4.1 1. ],label data:1\n",
      "input data : [6.2 2.2 4.5 1.5],label data:1\n",
      "input data : [5.6 2.5 3.9 1.1],label data:1\n",
      "input data : [5.9 3.2 4.8 1.8],label data:1\n",
      "input data : [6.1 2.8 4.  1.3],label data:1\n",
      "input data : [6.3 2.5 4.9 1.5],label data:1\n",
      "input data : [6.1 2.8 4.7 1.2],label data:1\n",
      "input data : [6.4 2.9 4.3 1.3],label data:1\n",
      "input data : [6.6 3.  4.4 1.4],label data:1\n",
      "input data : [6.8 2.8 4.8 1.4],label data:1\n",
      "input data : [6.7 3.  5.  1.7],label data:1\n",
      "input data : [6.  2.9 4.5 1.5],label data:1\n",
      "input data : [5.7 2.6 3.5 1. ],label data:1\n",
      "input data : [5.5 2.4 3.8 1.1],label data:1\n",
      "input data : [5.5 2.4 3.7 1. ],label data:1\n",
      "input data : [5.8 2.7 3.9 1.2],label data:1\n",
      "input data : [6.  2.7 5.1 1.6],label data:1\n",
      "input data : [5.4 3.  4.5 1.5],label data:1\n",
      "input data : [6.  3.4 4.5 1.6],label data:1\n",
      "input data : [6.7 3.1 4.7 1.5],label data:1\n",
      "input data : [6.3 2.3 4.4 1.3],label data:1\n",
      "input data : [5.6 3.  4.1 1.3],label data:1\n",
      "input data : [5.5 2.5 4.  1.3],label data:1\n",
      "input data : [5.5 2.6 4.4 1.2],label data:1\n",
      "input data : [6.1 3.  4.6 1.4],label data:1\n",
      "input data : [5.8 2.6 4.  1.2],label data:1\n",
      "input data : [5.  2.3 3.3 1. ],label data:1\n",
      "input data : [5.6 2.7 4.2 1.3],label data:1\n",
      "input data : [5.7 3.  4.2 1.2],label data:1\n",
      "input data : [5.7 2.9 4.2 1.3],label data:1\n",
      "input data : [6.2 2.9 4.3 1.3],label data:1\n",
      "input data : [5.1 2.5 3.  1.1],label data:1\n",
      "input data : [5.7 2.8 4.1 1.3],label data:1\n",
      "input data : [6.3 3.3 6.  2.5],label data:2\n",
      "input data : [5.8 2.7 5.1 1.9],label data:2\n",
      "input data : [7.1 3.  5.9 2.1],label data:2\n",
      "input data : [6.3 2.9 5.6 1.8],label data:2\n",
      "input data : [6.5 3.  5.8 2.2],label data:2\n",
      "input data : [7.6 3.  6.6 2.1],label data:2\n",
      "input data : [4.9 2.5 4.5 1.7],label data:2\n",
      "input data : [7.3 2.9 6.3 1.8],label data:2\n",
      "input data : [6.7 2.5 5.8 1.8],label data:2\n",
      "input data : [7.2 3.6 6.1 2.5],label data:2\n",
      "input data : [6.5 3.2 5.1 2. ],label data:2\n",
      "input data : [6.4 2.7 5.3 1.9],label data:2\n",
      "input data : [6.8 3.  5.5 2.1],label data:2\n",
      "input data : [5.7 2.5 5.  2. ],label data:2\n",
      "input data : [5.8 2.8 5.1 2.4],label data:2\n",
      "input data : [6.4 3.2 5.3 2.3],label data:2\n",
      "input data : [6.5 3.  5.5 1.8],label data:2\n",
      "input data : [7.7 3.8 6.7 2.2],label data:2\n",
      "input data : [7.7 2.6 6.9 2.3],label data:2\n",
      "input data : [6.  2.2 5.  1.5],label data:2\n",
      "input data : [6.9 3.2 5.7 2.3],label data:2\n",
      "input data : [5.6 2.8 4.9 2. ],label data:2\n",
      "input data : [7.7 2.8 6.7 2. ],label data:2\n",
      "input data : [6.3 2.7 4.9 1.8],label data:2\n",
      "input data : [6.7 3.3 5.7 2.1],label data:2\n",
      "input data : [7.2 3.2 6.  1.8],label data:2\n",
      "input data : [6.2 2.8 4.8 1.8],label data:2\n",
      "input data : [6.1 3.  4.9 1.8],label data:2\n",
      "input data : [6.4 2.8 5.6 2.1],label data:2\n",
      "input data : [7.2 3.  5.8 1.6],label data:2\n",
      "input data : [7.4 2.8 6.1 1.9],label data:2\n",
      "input data : [7.9 3.8 6.4 2. ],label data:2\n",
      "input data : [6.4 2.8 5.6 2.2],label data:2\n",
      "input data : [6.3 2.8 5.1 1.5],label data:2\n",
      "input data : [6.1 2.6 5.6 1.4],label data:2\n",
      "input data : [7.7 3.  6.1 2.3],label data:2\n",
      "input data : [6.3 3.4 5.6 2.4],label data:2\n",
      "input data : [6.4 3.1 5.5 1.8],label data:2\n",
      "input data : [6.  3.  4.8 1.8],label data:2\n",
      "input data : [6.9 3.1 5.4 2.1],label data:2\n",
      "input data : [6.7 3.1 5.6 2.4],label data:2\n",
      "input data : [6.9 3.1 5.1 2.3],label data:2\n",
      "input data : [5.8 2.7 5.1 1.9],label data:2\n",
      "input data : [6.8 3.2 5.9 2.3],label data:2\n",
      "input data : [6.7 3.3 5.7 2.5],label data:2\n",
      "input data : [6.7 3.  5.2 2.3],label data:2\n",
      "input data : [6.3 2.5 5.  1.9],label data:2\n",
      "input data : [6.5 3.  5.2 2. ],label data:2\n",
      "input data : [6.2 3.4 5.4 2.3],label data:2\n",
      "input data : [5.9 3.  5.1 1.8],label data:2\n",
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.3131 - loss: 1.1463 - val_accuracy: 0.3000 - val_loss: 1.1238\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3264 - loss: 1.1559 - val_accuracy: 0.3000 - val_loss: 1.0957\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2599 - loss: 1.1348 - val_accuracy: 0.2667 - val_loss: 1.0802\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2609 - loss: 1.0892 - val_accuracy: 0.3667 - val_loss: 1.0701\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3070 - loss: 1.0701 - val_accuracy: 0.3667 - val_loss: 1.0621\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2828 - loss: 1.0680 - val_accuracy: 0.3667 - val_loss: 1.0369\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4648 - loss: 1.0160 - val_accuracy: 0.4333 - val_loss: 0.9985\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6163 - loss: 0.9864 - val_accuracy: 0.7000 - val_loss: 0.9604\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7408 - loss: 0.9432 - val_accuracy: 0.7000 - val_loss: 0.9300\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6790 - loss: 0.9212 - val_accuracy: 0.7000 - val_loss: 0.9046\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6509 - loss: 0.8972 - val_accuracy: 0.7000 - val_loss: 0.8795\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6870 - loss: 0.8653 - val_accuracy: 0.7000 - val_loss: 0.8525\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5886 - loss: 0.8556 - val_accuracy: 0.7000 - val_loss: 0.8316\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6186 - loss: 0.8316 - val_accuracy: 0.7000 - val_loss: 0.8036\n",
      "Epoch 15/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7143 - loss: 0.7806 - val_accuracy: 0.7000 - val_loss: 0.7747\n",
      "Epoch 16/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6340 - loss: 0.7712 - val_accuracy: 0.7000 - val_loss: 0.7504\n",
      "Epoch 17/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7391 - loss: 0.7286 - val_accuracy: 0.7000 - val_loss: 0.7246\n",
      "Epoch 18/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5687 - loss: 0.7514 - val_accuracy: 0.7000 - val_loss: 0.7067\n",
      "Epoch 19/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6430 - loss: 0.6892 - val_accuracy: 0.7000 - val_loss: 0.6820\n",
      "Epoch 20/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6449 - loss: 0.6687 - val_accuracy: 0.7000 - val_loss: 0.6610\n",
      "Epoch 21/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6812 - loss: 0.6423 - val_accuracy: 0.7000 - val_loss: 0.6398\n",
      "Epoch 22/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6731 - loss: 0.6487 - val_accuracy: 0.7000 - val_loss: 0.6228\n",
      "Epoch 23/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6670 - loss: 0.6193 - val_accuracy: 0.7000 - val_loss: 0.6067\n",
      "Epoch 24/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6941 - loss: 0.5881 - val_accuracy: 0.7000 - val_loss: 0.5913\n",
      "Epoch 25/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6119 - loss: 0.6057 - val_accuracy: 0.7000 - val_loss: 0.5784\n",
      "Epoch 26/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6845 - loss: 0.5653 - val_accuracy: 0.7000 - val_loss: 0.5639\n",
      "Epoch 27/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6823 - loss: 0.5427 - val_accuracy: 0.7000 - val_loss: 0.5526\n",
      "Epoch 28/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5994 - loss: 0.5782 - val_accuracy: 0.7000 - val_loss: 0.5454\n",
      "Epoch 29/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6838 - loss: 0.5131 - val_accuracy: 0.7000 - val_loss: 0.5318\n",
      "Epoch 30/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6774 - loss: 0.5243 - val_accuracy: 0.7000 - val_loss: 0.5231\n",
      "Epoch 31/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6888 - loss: 0.5177 - val_accuracy: 0.7000 - val_loss: 0.5152\n",
      "Epoch 32/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6205 - loss: 0.5467 - val_accuracy: 0.7333 - val_loss: 0.5103\n",
      "Epoch 33/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6870 - loss: 0.5019 - val_accuracy: 0.7333 - val_loss: 0.5028\n",
      "Epoch 34/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7303 - loss: 0.5007 - val_accuracy: 0.7333 - val_loss: 0.4937\n",
      "Epoch 35/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6732 - loss: 0.4937 - val_accuracy: 0.7333 - val_loss: 0.4904\n",
      "Epoch 36/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7187 - loss: 0.4917 - val_accuracy: 0.7333 - val_loss: 0.4836\n",
      "Epoch 37/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7248 - loss: 0.4904 - val_accuracy: 0.7333 - val_loss: 0.4775\n",
      "Epoch 38/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6862 - loss: 0.5251 - val_accuracy: 0.7667 - val_loss: 0.4732\n",
      "Epoch 39/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7884 - loss: 0.4759 - val_accuracy: 0.8000 - val_loss: 0.4679\n",
      "Epoch 40/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7475 - loss: 0.4946 - val_accuracy: 0.8667 - val_loss: 0.4657\n",
      "Epoch 41/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8850 - loss: 0.4807 - val_accuracy: 0.8000 - val_loss: 0.4579\n",
      "Epoch 42/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7774 - loss: 0.4646 - val_accuracy: 0.8667 - val_loss: 0.4559\n",
      "Epoch 43/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8332 - loss: 0.4912 - val_accuracy: 0.8000 - val_loss: 0.4472\n",
      "Epoch 44/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8200 - loss: 0.4713 - val_accuracy: 0.7667 - val_loss: 0.4420\n",
      "Epoch 45/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7786 - loss: 0.4555 - val_accuracy: 0.8333 - val_loss: 0.4401\n",
      "Epoch 46/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8625 - loss: 0.4330 - val_accuracy: 0.8333 - val_loss: 0.4348\n",
      "Epoch 47/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8656 - loss: 0.4772 - val_accuracy: 0.9000 - val_loss: 0.4340\n",
      "Epoch 48/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9215 - loss: 0.4079 - val_accuracy: 0.9000 - val_loss: 0.4298\n",
      "Epoch 49/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9121 - loss: 0.4457 - val_accuracy: 0.8667 - val_loss: 0.4229\n",
      "Epoch 50/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8917 - loss: 0.4019 - val_accuracy: 0.8667 - val_loss: 0.4182\n",
      "Epoch 51/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8704 - loss: 0.4436 - val_accuracy: 0.8667 - val_loss: 0.4138\n",
      "Epoch 52/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8902 - loss: 0.4137 - val_accuracy: 0.8667 - val_loss: 0.4098\n",
      "Epoch 53/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9097 - loss: 0.4040 - val_accuracy: 0.9000 - val_loss: 0.4065\n",
      "Epoch 54/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9132 - loss: 0.3982 - val_accuracy: 0.9000 - val_loss: 0.4026\n",
      "Epoch 55/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8852 - loss: 0.4053 - val_accuracy: 0.8333 - val_loss: 0.4006\n",
      "Epoch 56/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9511 - loss: 0.3802 - val_accuracy: 0.9000 - val_loss: 0.3931\n",
      "Epoch 57/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9119 - loss: 0.3691 - val_accuracy: 0.8667 - val_loss: 0.3894\n",
      "Epoch 58/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9287 - loss: 0.4070 - val_accuracy: 0.8333 - val_loss: 0.3872\n",
      "Epoch 59/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9298 - loss: 0.3762 - val_accuracy: 0.9000 - val_loss: 0.3806\n",
      "Epoch 60/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9230 - loss: 0.4029 - val_accuracy: 0.9000 - val_loss: 0.3758\n",
      "Epoch 61/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9327 - loss: 0.3596 - val_accuracy: 0.8333 - val_loss: 0.3734\n",
      "Epoch 62/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9380 - loss: 0.3468 - val_accuracy: 0.9000 - val_loss: 0.3681\n",
      "Epoch 63/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9494 - loss: 0.3754 - val_accuracy: 0.8333 - val_loss: 0.3656\n",
      "Epoch 64/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9307 - loss: 0.3615 - val_accuracy: 0.8667 - val_loss: 0.3609\n",
      "Epoch 65/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9560 - loss: 0.3392 - val_accuracy: 0.8667 - val_loss: 0.3572\n",
      "Epoch 66/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9327 - loss: 0.3495 - val_accuracy: 0.9000 - val_loss: 0.3524\n",
      "Epoch 67/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9317 - loss: 0.3242 - val_accuracy: 0.8667 - val_loss: 0.3508\n",
      "Epoch 68/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9562 - loss: 0.3353 - val_accuracy: 0.8667 - val_loss: 0.3464\n",
      "Epoch 69/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9589 - loss: 0.3308 - val_accuracy: 0.9000 - val_loss: 0.3416\n",
      "Epoch 70/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9498 - loss: 0.3207 - val_accuracy: 0.8667 - val_loss: 0.3407\n",
      "Epoch 71/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9196 - loss: 0.3420 - val_accuracy: 0.9000 - val_loss: 0.3349\n",
      "Epoch 72/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9541 - loss: 0.3144 - val_accuracy: 0.8667 - val_loss: 0.3315\n",
      "Epoch 73/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.3195 - val_accuracy: 0.8667 - val_loss: 0.3303\n",
      "Epoch 74/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9657 - loss: 0.3537 - val_accuracy: 0.9000 - val_loss: 0.3239\n",
      "Epoch 75/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9724 - loss: 0.3075 - val_accuracy: 0.9000 - val_loss: 0.3206\n",
      "Epoch 76/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9570 - loss: 0.3211 - val_accuracy: 0.9000 - val_loss: 0.3202\n",
      "Epoch 77/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9490 - loss: 0.2757 - val_accuracy: 0.8667 - val_loss: 0.3159\n",
      "Epoch 78/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9480 - loss: 0.3125 - val_accuracy: 0.9000 - val_loss: 0.3107\n",
      "Epoch 79/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9444 - loss: 0.2851 - val_accuracy: 0.8667 - val_loss: 0.3080\n",
      "Epoch 80/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9559 - loss: 0.2763 - val_accuracy: 0.8667 - val_loss: 0.3046\n",
      "Epoch 81/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9275 - loss: 0.3034 - val_accuracy: 0.8667 - val_loss: 0.3026\n",
      "Epoch 82/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9644 - loss: 0.3001 - val_accuracy: 0.9000 - val_loss: 0.2981\n",
      "Epoch 83/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9503 - loss: 0.2900 - val_accuracy: 0.8667 - val_loss: 0.2959\n",
      "Epoch 84/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9520 - loss: 0.2630 - val_accuracy: 0.9000 - val_loss: 0.2940\n",
      "Epoch 85/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9572 - loss: 0.2696 - val_accuracy: 0.8667 - val_loss: 0.2896\n",
      "Epoch 86/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9771 - loss: 0.2477 - val_accuracy: 0.9000 - val_loss: 0.2868\n",
      "Epoch 87/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9771 - loss: 0.2495 - val_accuracy: 0.9000 - val_loss: 0.2847\n",
      "Epoch 88/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9501 - loss: 0.2866 - val_accuracy: 0.9333 - val_loss: 0.2801\n",
      "Epoch 89/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9639 - loss: 0.2333 - val_accuracy: 0.9000 - val_loss: 0.2777\n",
      "Epoch 90/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9637 - loss: 0.2408 - val_accuracy: 0.9000 - val_loss: 0.2768\n",
      "Epoch 91/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9665 - loss: 0.2460 - val_accuracy: 0.9000 - val_loss: 0.2732\n",
      "Epoch 92/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.2214 - val_accuracy: 0.9333 - val_loss: 0.2689\n",
      "Epoch 93/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9732 - loss: 0.2482 - val_accuracy: 0.9000 - val_loss: 0.2668\n",
      "Epoch 94/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9814 - loss: 0.2279 - val_accuracy: 0.9333 - val_loss: 0.2633\n",
      "Epoch 95/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9748 - loss: 0.2323 - val_accuracy: 0.9000 - val_loss: 0.2612\n",
      "Epoch 96/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9687 - loss: 0.2341 - val_accuracy: 0.9000 - val_loss: 0.2585\n",
      "Epoch 97/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9482 - loss: 0.2642 - val_accuracy: 0.9000 - val_loss: 0.2569\n",
      "Epoch 98/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9532 - loss: 0.2176 - val_accuracy: 0.9000 - val_loss: 0.2551\n",
      "Epoch 99/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9644 - loss: 0.2280 - val_accuracy: 0.9000 - val_loss: 0.2514\n",
      "Epoch 100/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9634 - loss: 0.2206 - val_accuracy: 0.9000 - val_loss: 0.2494\n",
      "Epoch 101/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9637 - loss: 0.2241 - val_accuracy: 0.9333 - val_loss: 0.2460\n",
      "Epoch 102/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9472 - loss: 0.2232 - val_accuracy: 0.9000 - val_loss: 0.2448\n",
      "Epoch 103/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9702 - loss: 0.1922 - val_accuracy: 0.9000 - val_loss: 0.2416\n",
      "Epoch 104/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9651 - loss: 0.2157 - val_accuracy: 0.9000 - val_loss: 0.2423\n",
      "Epoch 105/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9278 - loss: 0.2360 - val_accuracy: 0.9667 - val_loss: 0.2375\n",
      "Epoch 106/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9435 - loss: 0.2049 - val_accuracy: 0.9000 - val_loss: 0.2365\n",
      "Epoch 107/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9729 - loss: 0.1855 - val_accuracy: 0.9000 - val_loss: 0.2365\n",
      "Epoch 108/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9639 - loss: 0.2035 - val_accuracy: 0.9667 - val_loss: 0.2307\n",
      "Epoch 109/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9620 - loss: 0.1936 - val_accuracy: 0.9667 - val_loss: 0.2286\n",
      "Epoch 110/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9451 - loss: 0.2143 - val_accuracy: 0.9000 - val_loss: 0.2310\n",
      "Epoch 111/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9638 - loss: 0.1849 - val_accuracy: 0.9667 - val_loss: 0.2248\n",
      "Epoch 112/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9370 - loss: 0.1899 - val_accuracy: 0.9667 - val_loss: 0.2228\n",
      "Epoch 113/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9651 - loss: 0.1737 - val_accuracy: 0.9000 - val_loss: 0.2237\n",
      "Epoch 114/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9803 - loss: 0.1636 - val_accuracy: 0.9667 - val_loss: 0.2190\n",
      "Epoch 115/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9765 - loss: 0.1662 - val_accuracy: 0.9000 - val_loss: 0.2182\n",
      "Epoch 116/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9722 - loss: 0.2002 - val_accuracy: 0.9000 - val_loss: 0.2156\n",
      "Epoch 117/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9726 - loss: 0.1674 - val_accuracy: 0.9000 - val_loss: 0.2146\n",
      "Epoch 118/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9832 - loss: 0.1644 - val_accuracy: 0.9667 - val_loss: 0.2122\n",
      "Epoch 119/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9814 - loss: 0.1542 - val_accuracy: 0.9000 - val_loss: 0.2154\n",
      "Epoch 120/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9726 - loss: 0.1919 - val_accuracy: 0.9000 - val_loss: 0.2087\n",
      "Epoch 121/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9541 - loss: 0.1898 - val_accuracy: 0.9000 - val_loss: 0.2082\n",
      "Epoch 122/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9547 - loss: 0.1760 - val_accuracy: 0.9667 - val_loss: 0.2055\n",
      "Epoch 123/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9699 - loss: 0.1459 - val_accuracy: 0.9000 - val_loss: 0.2064\n",
      "Epoch 124/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9778 - loss: 0.1667 - val_accuracy: 0.9000 - val_loss: 0.2027\n",
      "Epoch 125/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9597 - loss: 0.1796 - val_accuracy: 0.9000 - val_loss: 0.2021\n",
      "Epoch 126/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9837 - loss: 0.1331 - val_accuracy: 0.9667 - val_loss: 0.1994\n",
      "Epoch 127/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9748 - loss: 0.1489 - val_accuracy: 0.9000 - val_loss: 0.1991\n",
      "Epoch 128/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9746 - loss: 0.1488 - val_accuracy: 0.9000 - val_loss: 0.1976\n",
      "Epoch 129/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9896 - loss: 0.1208 - val_accuracy: 0.9000 - val_loss: 0.1953\n",
      "Epoch 130/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9562 - loss: 0.1640 - val_accuracy: 0.9000 - val_loss: 0.1949\n",
      "Epoch 131/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9609 - loss: 0.1518 - val_accuracy: 0.9667 - val_loss: 0.1923\n",
      "Epoch 132/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9807 - loss: 0.1292 - val_accuracy: 0.9000 - val_loss: 0.1919\n",
      "Epoch 133/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9631 - loss: 0.1500 - val_accuracy: 0.9000 - val_loss: 0.1909\n",
      "Epoch 134/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9643 - loss: 0.1492 - val_accuracy: 0.9667 - val_loss: 0.1884\n",
      "Epoch 135/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9781 - loss: 0.1396 - val_accuracy: 0.9000 - val_loss: 0.1885\n",
      "Epoch 136/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.1445 - val_accuracy: 0.9000 - val_loss: 0.1875\n",
      "Epoch 137/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.1358 - val_accuracy: 0.9667 - val_loss: 0.1848\n",
      "Epoch 138/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9455 - loss: 0.1752 - val_accuracy: 0.9000 - val_loss: 0.1840\n",
      "Epoch 139/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9875 - loss: 0.1239 - val_accuracy: 0.9000 - val_loss: 0.1862\n",
      "Epoch 140/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9643 - loss: 0.1483 - val_accuracy: 0.9000 - val_loss: 0.1820\n",
      "Epoch 141/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9651 - loss: 0.1341 - val_accuracy: 0.9000 - val_loss: 0.1824\n",
      "Epoch 142/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9752 - loss: 0.1080 - val_accuracy: 0.9667 - val_loss: 0.1803\n",
      "Epoch 143/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9504 - loss: 0.1486 - val_accuracy: 0.9000 - val_loss: 0.1794\n",
      "Epoch 144/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9729 - loss: 0.1385 - val_accuracy: 0.9000 - val_loss: 0.1790\n",
      "Epoch 145/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9597 - loss: 0.1261 - val_accuracy: 0.9333 - val_loss: 0.1761\n",
      "Epoch 146/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9541 - loss: 0.1409 - val_accuracy: 0.9000 - val_loss: 0.1776\n",
      "Epoch 147/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9832 - loss: 0.1278 - val_accuracy: 0.9000 - val_loss: 0.1760\n",
      "Epoch 148/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9586 - loss: 0.1451 - val_accuracy: 0.9667 - val_loss: 0.1730\n",
      "Epoch 149/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9597 - loss: 0.1312 - val_accuracy: 0.9000 - val_loss: 0.1728\n",
      "Epoch 150/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9789 - loss: 0.1221 - val_accuracy: 0.9000 - val_loss: 0.1733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.9000 - loss: 0.1733\n",
      "loss : 0.17333076894283295\n",
      "accuracy:0.8999999761581421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "[6.1, 2.8, 4.7, 1.2]=> 1 (expected 1)\n",
      "[5.7, 3.8, 1.7, 0.3]=> 0 (expected 0)\n",
      "[7.7, 2.6, 6.9, 2.3]=> 2 (expected 2)\n",
      "[6.0, 2.9, 4.5, 1.5]=> 1 (expected 1)\n",
      "[6.8, 2.8, 4.8, 1.4]=> 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "dataset=load_iris()\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(f\"input data : {X[i]},label data:{y[i]}\")\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=4,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=150,batch_size=10,validation_data=(X_test,y_test))\n",
    "\n",
    "loss,accuracy= model.evaluate(X_test,y_test)\n",
    "print(f\"loss : {loss}\")\n",
    "print(f\"accuracy:{accuracy}\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predictions=model.predict(X_test)\n",
    "predicted_classes=np.argmax(predictions,axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "          print(\"%s=> %d (expected %d)\"%(X_test[i].tolist(),predicted_classes[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8640ae36-582c-4b64-aa64-23e050526b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "[5.1, 3.5, 1.4, 0.0] => 0 (expected 0)\n"
     ]
    }
   ],
   "source": [
    "# predict it on a specified input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sample_input = np.array([[5.1, 3.5, 1.4, 0]]) \n",
    "\n",
    "prediction = model.predict(sample_input)\n",
    "prediction_class=np.argmax(prediction)\n",
    "\n",
    "print(\"%s => %d (expected %d)\" %(sample_input[0].tolist(),prediction_class,y[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cff85-578e-474e-a46b-3f0319c6e784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
